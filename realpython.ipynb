{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Descriptive Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive Statistics** is about describing and summarizing data, using 2 main approaches\n",
    "1. Quantitative Approach: describes and summarizes data numerically.\n",
    "2. Visual Approach: illustrates data with charts, plots, histograms, and other graphs.\n",
    "\n",
    "Types of Measures:\n",
    "1. Central tendency: describes centers of the data. (e.g. mean, median, mode)\n",
    "2. Variability: describes the spread of the data. (e.g. variance, standard deviation)\n",
    "3. Correlation or Joint variability: describes the relation between a pair of variables in a dataset. (e.g. covariance, correlation efficient)\n",
    "\n",
    "- Population: set of all elements or items that youâ€™re interested in\n",
    "- Sample: subset of a population\n",
    "- Outliers: data point that differs significantly from the majority of the data taken from a sample or population.\n",
    "- Causes of Outliers:\n",
    "    - Natural variation in data\n",
    "    - Change in the behavior of the observed system\n",
    "    - Errors in data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Libraries for Statistical Calculations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pythonâ€™s **statistics**: built-in Python library for descriptive statistics. You can use it if your datasets are not too large or if you canâ€™t rely on importing other libraries.\n",
    "\n",
    "2. **NumPy**: third-party library for numerical computing, optimized for working with single- and multi-dimensional arrays. Its primary type is the array type called ndarray. This library contains many routines for statistical analysis.\n",
    "\n",
    "3. **SciPy**: third-party library for scientific computing based on NumPy. It offers additional functionality compared to NumPy, including scipy.stats for statistical analysis.\n",
    "\n",
    "4. **Pandas**: third-party library for numerical computing based on NumPy. It excels in handling labeled one-dimensional (1D) data with Series objects and two-dimensional (2D) data with DataFrame objects.\n",
    "\n",
    "5. **Matplotlib**: third-party library for data visualization. It works well in combination with NumPy, SciPy, and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics # for descriptive statistics\n",
    "import numpy as np # for single/multi dimensional arrays\n",
    "import scipy.stats # scientific computing based on numpy\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot # for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculating Descriptive Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating arbitrary data to work with\n",
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0]\n",
    "x\n",
    "\n",
    "x_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan = not-a-number value\n",
    "You can use any of the following interchangeably to get a NaN value:\n",
    "float('nan')\n",
    "math.nan\n",
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.isnan(np.nan), np.isnan(math.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create np.ndarray and pd.Series objects that correspond to x and x_with_nan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_with_nan = np.array(x), np.array(x_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, z_with_nan = pd.Series(x), pd.Series(x_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Measures of Central Tendency**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mean/Average\n",
    "2. Weighted mean/Weighted avg\n",
    "3. Geometric mean\n",
    "4. Harmonic mean\n",
    "5. Median\n",
    "6. Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can calculate the mean with pure Python using sum() and len()\n",
    "mean_ = sum(x) / len(x)\n",
    "mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also apply built-in Python statistics functions\n",
    "mean_ = statistics.mean(x)\n",
    "mean_\n",
    "\n",
    "mean_ = statistics.fmean(x)\n",
    "mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are NaN values among your data, then statistics.mean() and statistics.fmean() will return nan as the output:\n",
    "mean_ = statistics.mean(x_with_nan)\n",
    "mean_\n",
    "\n",
    "mean_ = statistics.fmean(x_with_nan)\n",
    "mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you use NumPy, then you can get the mean with np.mean():\n",
    "mean_ = np.mean(y)\n",
    "mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the example above, mean() is a function, but you can use the corresponding method .mean() as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = y.mean()\n",
    "mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mean() and .mean() from NumPy returns same result as statistics.mean(). Also, same result if there are NaN values among your data:\n",
    "np.mean(y_with_nan)\n",
    "\n",
    "y_with_nan.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can ignore all NaN vaules by using np.nanmean(), which returns same value as mean()\n",
    "np.nanmean(y_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series objects also have the method .mean() and ignores NaN values by default:\n",
    "mean_ = z.mean()\n",
    "mean_\n",
    "z_with_nan.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Mean**\n",
    "- very handy when you need the mean of a dataset containing items that occur with given relative frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary dataset\n",
    "0.2 * 2 + 0.5 * 4 + 0.3 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use weighted mean in pure Python (no libraries) by combining sum() with either range() or zip():\n",
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "w = [0.1, 0.2, 0.3, 0.25, 0.15]\n",
    "wmean = sum(w[i] * x[i] for i in range(len(x))) / sum(w)\n",
    "wmean\n",
    "\n",
    "wmean = sum(x_ * w_ for (x_, w_) in zip(x, w)) / sum(w)\n",
    "wmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have large datasets, using NumPy np.average is better\n",
    "y, z, w = np.array(x), pd.Series(x), np.array(w)\n",
    "wmean = np.average(y, weights=w)\n",
    "wmean\n",
    "\n",
    "wmean = np.average(z, weights=w)\n",
    "wmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this method on ordinary lists and tuples.\n",
    "# Or you can use w * y with np.sum() or .sum():\n",
    "(w * y).sum() / w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful if your dataset contains nan values:\n",
    "w = np.array([0.1, 0.2, 0.3, 0.0, 0.2, 0.1])\n",
    "(w * y_with_nan).sum() / w.sum()\n",
    "\n",
    "np.average(y_with_nan, weights=w)\n",
    "\n",
    "np.average(z_with_nan, weights=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harmonic Mean**\n",
    "-  reciprocal of the mean of the reciprocals of all items in the dataset: ğ‘› / Î£áµ¢(1/ğ‘¥áµ¢), where ğ‘– = 1, 2, â€¦, ğ‘› and ğ‘› is the number of items in the dataset ğ‘¥. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean = len(x) / sum(1 / item for item in x)\n",
    "hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can use statistics.harmonic_mean():\n",
    "hmean = statistics.harmonic_mean(x)\n",
    "hmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a nan value in a dataset, returns nan.\n",
    "statistics.harmonic_mean(x_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have at least one 0, returns 0\n",
    "\n",
    "statistics.harmonic_mean([1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have at least one negative number, returns statistics.StatisticsError \n",
    "statistics.harmonic_mean([1, 2, -2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also can use: scipy.stats.hmean():\n",
    "scipy.stats.hmean(y)\n",
    "\n",
    "scipy.stats.hmean(z)\n",
    "\n",
    "# if your dataset contains nan, 0, a negative number, or anything but positive numbers, then youâ€™ll get a ValueError!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geometric Mean** \n",
    "-  the ğ‘›-th root of the product of all ğ‘› elements ğ‘¥áµ¢ in a dataset ğ‘¥: â¿âˆš(Î áµ¢ğ‘¥áµ¢), where ğ‘– = 1, 2, â€¦, ğ‘›."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean = 1\n",
    "for item in x:\n",
    "    gmean *= item\n",
    "\n",
    "gmean **= 1 / len(x)\n",
    "gmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.8 introduced statistics.geometric_mean(), which converts all values to floating-point numbers and returns their geometric mean:\n",
    "gmean = statistics.geometric_mean(x)\n",
    "gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you pass data with nan values, then statistics.geometric_mean() will behave like most similar functions and return nan:\n",
    "gmean = statistics.geometric_mean(x_with_nan)\n",
    "gmean\n",
    "\n",
    "#  If thereâ€™s a zero or negative number among your data, then statistics.geometric_mean() will raise the statistics.StatisticsError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use:\n",
    "scipy.stats.gmean(y)\n",
    "\n",
    "scipy.stats.gmean(z)\n",
    "\n",
    "# If you have nan values in a dataset, then gmean() will return nan. \n",
    "# If thereâ€™s at least one 0, then itâ€™ll return 0.0 and give a warning. \n",
    "# If you provide at least one negative number, then youâ€™ll get nan and the warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median** \n",
    "- the middle element of a sorted dataset (increasing or decreasing order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the elements of the dataset\n",
    "#Finding the middle element(s) in the sorted dataset\n",
    "\n",
    "n = len(x)\n",
    "if n % 2:\n",
    "    median_ = sorted(x)[round(0.5*(n-1))]\n",
    "else:\n",
    "    x_ord, index = sorted(x), round(0.5 * n)\n",
    "    median_ = 0.5 * (x_ord[index-1] + x_ord[index])\n",
    "\n",
    "median_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ = statistics.median(x) # odd number of elements\n",
    "median_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-1 is without the last item 28\n",
    "median_ = statistics.median(x[:-1]) ##even number of elements\n",
    "median_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If nbumber of elements is EVEN, use median_low() and median_high() to returnthe 2 middle values\n",
    "statistics.median_low(x[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median_high(x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are nan values using median, median_low, median_high, doesn't return nan \n",
    "statistics.median(x_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median_low(x_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median_high(x_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use np,.median() to get median\n",
    "median_ = np.median(y)\n",
    "median_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use np,.median() to get median\n",
    "median_ = np.median(y[:-1])\n",
    "median_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  if thereâ€™s a nan value in your dataset, then np.median() issues the RuntimeWarning and returns nan. \n",
    "# If this behavior is not what you want, then you can use nanmedian() to ignore all nan values:\n",
    "np.nanmedian(y_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(y_with_nan[:-1])\n",
    "\n",
    "# The obtained results are the same as with statistics.median() and np.median() applied to the datasets x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series objects have the method .median() that ignores nan values by default:\n",
    "z.median()\n",
    "\n",
    "z_with_nan.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mode**\n",
    "- the value in the dataset that occurs most frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure python\n",
    "u = [2, 3, 2, 8, 12]\n",
    "mode_ = max((u.count(item), item) for item in set(u))[1]\n",
    "mode_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can obtain the mode with statistics.mode() and statistics.multimode():\n",
    "mode_ = statistics.mode(u) # mode() returns isngle value\n",
    "mode_\n",
    "mode_ = statistics.multimode(u) #multimode() returns the list that contains the result\n",
    "mode_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [12, 15, 12, 15, 21, 15, 12]\n",
    "statistics.mode(v)  # Raises StatisticsError\n",
    "statistics.multimode(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics.mode() and statistics.multimode() handle nan values as regular values and can return nan as the modal value:\n",
    "statistics.mode([2, math.nan, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.multimode([2, math.nan, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mode([2, math.nan, 0, math.nan, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.multimode([2, math.nan, 0, math.nan, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also get the mode with scipy.stats.mode():\n",
    "u, v = np.array(u), np.array(v)\n",
    "mode_ = scipy.stats.mode(u)\n",
    "mode_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_ = scipy.stats.mode(v)\n",
    "mode_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the mode and its number of occurrences as NumPy arrays with dot notation:\n",
    "mode_.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series objects have the method .mode() that handles multimodal values well and ignores nan values by default:\n",
    "u, v, w = pd.Series(u), pd.Series(v), pd.Series([2, 2, math.nan])\n",
    "u.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Variabiilty\n",
    "\n",
    "- Variance\n",
    "- Standard deviation\n",
    "- Skewness\n",
    "- Percentiles\n",
    "- Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance**\n",
    "- quanitfies the spread of the data\n",
    "- shows numerically how far the data points are from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure Python\n",
    "n = len(x)\n",
    "mean_ = sum(x) / n\n",
    "var_ = sum((item - mean_)**2 for item in x) / (n - 1)\n",
    "var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or existing function statistics.variance():\n",
    "var_ = statistics.variance(x)\n",
    "var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have nan values among your data, then statistics.variance() will return nan:\n",
    "statistics.variance(x_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy: use the function np.var() or the corresponding method .var():\n",
    "var_ = np.var(y, ddof=1)\n",
    "var_\n",
    "\n",
    "var_ = y.var(ddof=1)\n",
    "var_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have nan values in the dataset, then np.var() and .var() will return nan:\n",
    "np.var(y_with_nan, ddof=1)\n",
    "\n",
    "y_with_nan.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to skip nan values, then you should use np.nanvar():\n",
    "np.nanvar(y_with_nan, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to specify ddof=1\n",
    "\n",
    "np.nanvar(y_with_nan, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series objects have the method .var() that skips nan values by default:\n",
    "z.var(ddof=1)\n",
    "\n",
    "z_with_nan.var(ddof=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Deviation** \n",
    "- another measure of data spread\n",
    "- connected to the sample variance, as standard deviation, ğ‘ , is the positive square root of the sample variance. \n",
    "- often more convenient than the variance because it has the same unit as the data points. \n",
    "- Once you get the variance, you can calculate the standard deviation with pure Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ = var_ ** 0.5\n",
    "std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or can use statistics.stdev():\n",
    "std_ = statistics.stdev(x)\n",
    "std_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "np.std(y, ddof=1)\n",
    "\n",
    "y.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "np.std(y_with_nan, ddof=1)\n",
    "y_with_nan.std(ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "np.nanstd(y_with_nan, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas, skips nan by default\n",
    "\n",
    "z.std(ddof=1)\n",
    "\n",
    "z_with_nan.std(ddof=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Population Standard Deviation**\n",
    "- refers to the entire population \n",
    "- Find the square root of the population variance in the pure Python implementation.\n",
    "- Use statistics.pstdev() instead of statistics.stdev().\n",
    "- Specify the parameter ddof=0 if you use NumPy or Pandas. In NumPy, you can omit ddof because its default value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skewness**\n",
    "- measures the asymmetry of a data sample\n",
    "- negative skewness values: indicate that thereâ€™s a dominant tail on the left side\n",
    "- Positive skewness values correspond to a longer or fatter tail on the right side \n",
    "- If the skewness is close to 0 (for example, between âˆ’0.5 and 0.5), then the dataset is considered quite symmetrical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure python\n",
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "n = len(x)\n",
    "mean_ = sum(x) / n\n",
    "var_ = sum((item - mean_)**2 for item in x) / (n - 1)\n",
    "std_ = var_ ** 0.5\n",
    "skew_ = (sum((item - mean_)**3 for item in x)\n",
    "         * n / ((n - 1) * (n - 2) * std_**3))\n",
    "skew_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample skewness with scipy\n",
    "y, y_with_nan = np.array(x), np.array(x_with_nan)\n",
    "scipy.stats.skew(y, bias=False)\n",
    "\n",
    "scipy.stats.skew(y_with_nan, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas\n",
    "z, z_with_nan = pd.Series(x), pd.Series(x_with_nan)\n",
    "z.skew()\n",
    "\n",
    "z_with_nan.skew()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percentiles**\n",
    "- the element in the dataset such that p% of the elements in the dataset are less than or equal to that value\n",
    "Each dataset has three quartiles, which are the percentiles that divide the dataset into four parts:\n",
    "\n",
    "- first quartile is the sample 25th percentile. It divides roughly 25% of the smallest items from the rest of the dataset.\n",
    "- second quartile is the sample 50th percentile or the median. Approximately 25% of the items lie between the first and second quartiles and another 25% between the second and third quartiles.\n",
    "- third quartile is the sample 75th percentiles.  It divides roughly 25% of the largest items from the rest of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each part has approximately the same number of items. \n",
    "# If you want to divide your data into several intervals, then you can use statistics.quantiles():\n",
    "x = [-5.0, -1.1, 0.1, 2.0, 8.0, 12.8, 21.0, 25.8, 41.0]\n",
    "statistics.quantiles(x, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.quantiles(x, n=4, method='inclusive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 5th percentile\n",
    "y = np.array(x)\n",
    "np.percentile(y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find 95th percentile\n",
    "np.percentile(y, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(y, [25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to ignore nan values, then use np.nanpercentile() instead:\n",
    "y_with_nan = np.insert(y, 2, np.nan)\n",
    "y_with_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(y_with_nan, [25, 50, 75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "np.quantile(y, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(y, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(y, [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanquantile(y_with_nan, [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series objects have the method .quantile():\n",
    "z, z_with_nan = pd.Series(y), pd.Series(y_with_nan)\n",
    "z.quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_with_nan.quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranges**\n",
    "- the difference btwn the max and min element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ptp(y)\n",
    "\n",
    "np.ptp(z)\n",
    "\n",
    "np.ptp(z_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ptp(y_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(y) - np.amin(y)\n",
    "\n",
    "np.nanmax(y_with_nan) - np.nanmin(y_with_nan)\n",
    "\n",
    "y.max() - y.min()\n",
    "\n",
    "z.max() - z.min()\n",
    "\n",
    "z_with_nan.max() - z_with_nan.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interquartile range\n",
    "\n",
    "quartiles = np.quantile(y, [0.25, 0.75])\n",
    "quartiles[1] - quartiles[0]\n",
    "\n",
    "quartiles = z.quantile([0.25, 0.75])\n",
    "quartiles[0.75] - quartiles[0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe() returns an object that holds the following descriptive statistics:\n",
    "\n",
    "- nobs: the number of observations or elements in your dataset\n",
    "- minmax: the tuple with the minimum and maximum values of your dataset\n",
    "- mean: the mean of your dataset\n",
    "- variance: the variance of your dataset\n",
    "- skewness: the skewness of your dataset\n",
    "- kurtosis: the kurtosis of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.stats.describe(y, ddof=1, bias=False)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.minmax[0]  # Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.minmax[1]  # Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas has similar, if not better, functionality. Series objects have the method .describe():\n",
    "result = z.describe()\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['mean']\n",
    "\n",
    "result['std']\n",
    "\n",
    "result['min']\n",
    "\n",
    "result['max']\n",
    "\n",
    "result['25%']\n",
    "\n",
    "result['50%']\n",
    "\n",
    "result['75%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measures of Correlation Between Pairs of Data**\n",
    "- Youâ€™ll see the following measures of correlation between pairs of data:\n",
    "\n",
    "- Positive correlation exists when larger values of ğ‘¥ correspond to larger values of ğ‘¦ and vice versa.\n",
    "- Negative correlation exists when larger values of ğ‘¥ correspond to smaller values of ğ‘¦ and vice versa.\n",
    "- Weak or no correlation exists if there is no such apparent relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(-10, 11))\n",
    "y = [0, 2, 2, 2, 2, 3, 3, 6, 7, 4, 7, 6, 6, 9, 4, 5, 5, 10, 11, 12, 14]\n",
    "x_, y_ = np.array(x), np.array(y)\n",
    "x__, y__ = pd.Series(x_), pd.Series(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covariance**\n",
    "- the measure quanbtifies the strength and direction of relationship between a pair of variables \n",
    "- If the correlation is positive, then the covariance is positive, as well. A stronger relationship corresponds to a higher value of the covariance.\n",
    "- If the correlation is negative, then the covariance is negative, as well. A stronger relationship corresponds to a lower (or higher absolute) value of the covariance.\n",
    "- If the correlation is weak, then the covariance is close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure python \n",
    "n = len(x)\n",
    "mean_x, mean_y = sum(x) / n, sum(y) / n\n",
    "cov_xy = (sum((x[k] - mean_x) * (y[k] - mean_y) for k in range(n))\n",
    "          / (n - 1))\n",
    "cov_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "cov_matrix = np.cov(x_, y_)\n",
    "cov_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_.var(ddof=1)\n",
    "\n",
    "y_.var(ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other two elements of the covariance matrix are equal and represent the actual covariance between x and y:\n",
    "cov_xy = cov_matrix[0, 1]\n",
    "cov_xy\n",
    "\n",
    "cov_xy = cov_matrix[1, 0]\n",
    "cov_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "cov_xy = x__.cov(y__)\n",
    "cov_xy\n",
    "\n",
    "cov_xy = y__.cov(x__)\n",
    "cov_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Coeffienct**\n",
    "- pearson product-moment correlation coefficient (denoted as r)\n",
    "- The value ğ‘Ÿ > 0 indicates positive correlation.\n",
    "- The value ğ‘Ÿ < 0 indicates negative correlation.\n",
    "- The value r = 1 is the maximum possible value of ğ‘Ÿ. It corresponds to a perfect positive linear relationship between variables.\n",
    "- The value r = âˆ’1 is the minimum possible value of ğ‘Ÿ. It corresponds to a perfect negative linear relationship between variables.\n",
    "- The value r â‰ˆ 0, or when ğ‘Ÿ is around zero, means that the correlation between variables is weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pure python \n",
    "var_x = sum((item - mean_x)**2 for item in x) / (n - 1)\n",
    "var_y = sum((item - mean_y)**2 for item in y) / (n - 1)\n",
    "std_x, std_y = var_x ** 0.5, var_y ** 0.5\n",
    "r = cov_xy / (std_x * std_y)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats has the routine pearsonr() that calculates the correlation coefficient and the ğ‘-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = scipy.stats.pearsonr(x_, y_)\n",
    "r\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and get the correlation coefficient matrix: \n",
    "corr_matrix = np.corrcoef(x_, y_)\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = corr_matrix[0, 1]\n",
    "r\n",
    "\n",
    "r = corr_matrix[1, 0]\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.linregress(x_, y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.stats.linregress(x_, y_)\n",
    "r = result.rvalue\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = x__.corr(y__)\n",
    "r\n",
    "\n",
    "r = y__.corr(x__)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working with 2D Data** (db tables, csv, excel, calc, google spreadsheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by creating a 2d numpy array\n",
    "a = np.array([[1, 1, 1],\n",
    "              [2, 3, 1],\n",
    "              [4, 9, 2],\n",
    "              [8, 27, 4],\n",
    "              [16, 1, 1]])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a, axis=0)\n",
    "\n",
    "a.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a, axis=1)\n",
    "\n",
    "a.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(a, axis=0)\n",
    "\n",
    "np.median(a, axis=1)\n",
    "\n",
    "a.var(axis=0, ddof=1)\n",
    "\n",
    "a.var(axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.gmean(a)  # Default: axis=0\n",
    "\n",
    "scipy.stats.gmean(a, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.gmean(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.gmean(a, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.describe(a, axis=None, ddof=1, bias=False)\n",
    "\n",
    "scipy.stats.describe(a, ddof=1, bias=False)  # Default: axis=0\n",
    "\n",
    "scipy.stats.describe(a, axis=1, ddof=1, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.stats.describe(a, axis=1, ddof=1, bias=False)\n",
    "result.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = ['first', 'second', 'third', 'fourth', 'fifth']\n",
    "col_names = ['A', 'B', 'C']\n",
    "df = pd.DataFrame(a, index=row_names, columns=col_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()\n",
    "df.var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=1)\n",
    "df.var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'].mean()\n",
    "\n",
    "df['A'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values\n",
    "df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting Data: \n",
    "- Box plots\n",
    "- Histograms\n",
    "- Pie charts\n",
    "- Bar charts\n",
    "- X-Y plots\n",
    "- Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box PLots**\n",
    "-  excellent tool to visually represent descriptive statistics of a given dataset. It can show the range, interquartile range, median, mode, outliers, and all quartiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arbitrary data\n",
    "np.random.seed(seed=0)\n",
    "x = np.random.randn(1000)\n",
    "y = np.random.randn(100)\n",
    "z = np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot((x, y, z), vert=False, showmeans=True, meanline=True,\n",
    "           labels=('x', 'y', 'z'), patch_artist=True,\n",
    "           medianprops={'linewidth': 2, 'color': 'purple'},\n",
    "           meanprops={'linewidth': 2, 'color': 'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of .boxplot() define the following:\n",
    "\n",
    "- x is your data.\n",
    "- vert sets the plot orientation to horizontal when False. The default orientation is vertical.\n",
    "- showmeans shows the mean of your data when True.\n",
    "- meanline represents the mean as a line when True. The default representation is a point.\n",
    "- labels: the labels of your data.\n",
    "- patch_artist determines how to draw the graph.\n",
    "- medianprops denotes the properties of the line representing the median.\n",
    "- meanprops indicates the properties of the line or dot representing the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms**\n",
    "- particularly useful when there are a large number of unique values in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bin_edges = np.histogram(x, bins=10)\n",
    "hist\n",
    "\n",
    "bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(x, bin_edges, cumulative=False)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(x, bin_edges, cumulative=True)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pie Charts**\n",
    "- represent data with a small number of labels and given relative frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s define data associated to three labels:\n",
    "x, y, z = 128, 256, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a pie chart with .pie():\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie((x, y, z), labels=('x', 'y', 'z'), autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar Charts**\n",
    "-  illustrate data that correspond to given labels or discrete numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(21)\n",
    "y = np.random.randint(21, size=21)\n",
    "err = np.random.randn(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(x, y, yerr=err)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X-Y Plots or Scatter Plot**\n",
    "- represents the pairs of data from two datasets. \n",
    "- The horizontal x-axis shows the values from the set x, while the vertical y-axis shows the corresponding values from the set y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(21)\n",
    "y = 5 + 2 * x + 2 * np.random.randn(21)\n",
    "slope, intercept, r, *__ = scipy.stats.linregress(x, y)\n",
    "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, linewidth=0, marker='s', label='Data points')\n",
    "ax.plot(x, intercept + slope * x, label=line)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend(facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmaps**\n",
    "-  used to visually show a matrix. \n",
    "- The colors represent the numbers or elements of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.cov(x, y).round(decimals=2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(matrix)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('x', 'y'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('x', 'y'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, matrix[i, j], ha='center', va='center', color='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.corrcoef(x, y).round(decimals=2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(matrix)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('x', 'y'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('x', 'y'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, matrix[i, j], ha='center', va='center', color='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57ce36cfcf249843349f3236835148d06497510cfc71a5adee1576d1704ee7ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
